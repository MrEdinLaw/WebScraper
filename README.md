# Web Scrapper (Just emails right now)
> Scrapes multiple domains for emails and saves them in files per domain.

[![Build Status][travis-image]][travis-url]

## Installation

```
pip install -r requirements.txt
```

## Usage example

Copy/Paste the links you want to get scraped in the websites.txt (row per row).
Copy/Paste just the domain or a precize part of the website (more info in the wiki).
Edit the banned.txt if you want to ban more link parts.

_For more examples and usage, please refer to the [Wiki][wiki]._


## Release History

* 0.0.1
    * First Release

## Meta

MrEdinLaw â€“ [@MrEdinLaw](https://twitter.com/mredinlaw)

[https://github.com/mredinlaw/github-link](https://github.com/mredinlaw/)

## Contributing

1. Fork it (<https://github.com/mredinlaw/WebScraper/fork>)
2. Create your feature branch (`git checkout -b feature/myFeature`)
3. Commit your changes (`git commit -am 'Add some myFeature'`)
4. Push to the branch (`git push origin feature/myFeature`)
5. Create a new Pull Request

<!-- Markdown link & img dfn's -->
[travis-image]: https://img.shields.io/travis/dbader/node-datadog-metrics/master.svg?style=flat-square
[travis-url]: https://travis-ci.org/dbader/node-datadog-metrics
[wiki]: https://github.com/yourname/yourproject/wiki
